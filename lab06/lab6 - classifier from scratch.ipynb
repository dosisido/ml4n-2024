{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb55203",
   "metadata": {},
   "source": [
    "<center><b><font size=6>Lab-6 A classifier from scratch<b><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cdfedd",
   "metadata": {},
   "source": [
    "### Objective: Implement, use and evaluate a classifier (without using specific libraries such as sklearn)\n",
    "1. **Logistic regression** is a binary classification method that maps a linear combination of parameters and variables into two possible classes. Here, you will implement the logistic regression from scratch to better understand how an ML algorithm works. Useful link: <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\">Wiki</a>.\n",
    "2. **Performance evaluation metrics** are needed to evaluate the outcome of prediction with respect to true labels. Here, you will implement confusion matrix, accuracy, precision, recall and F-measure. Useful link: <a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\">Wiki</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c4ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed python libraries\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8044030",
   "metadata": {},
   "source": [
    "### 1. Dataset - TCP logs\n",
    "The dataset contains traffic information generated by an open-source passive network monitoring tool, namely **tstat**. It automates the collection of packet statistics of traffic aggregates, using real-time monitoring features. Being a passive tool, the typical usage scenario is live monitoring of Internet links, in which all transmitted packets are observed. In case of TCP, Tstat identifies a new flow start when it observes a TCP three-way handshake. Similarly, it identifies a TCP flow end either when it sees the TCP connection teardown, or when it doesn’t observe packets for some time (idle time). A flow is defined by a unique link between the sender and receiver, e.g., a tuple of <em>(IP_Protocol_Type, IP_Source_Address, Source_Port, IP_Destination_Address, Destination_Port)</em>. For a specific flow, tstat calculates a number of statistics of all the packets transmitted over this flow, and then generate a log for such flow with multiple attributes (statistics). A log file is arranged as a simple table where each column is associated to specific information and each row reports the flow during a connection. The log information is a summary of the flow properties. For instance, in the TCP log we can find columns like the starting time of a TCP connection, its duration, the number of sent and received packets, the observed Round Trip Time.\n",
    "![](tstat.png)\n",
    "\n",
    "In this lab, since the focus is on the development of logistic regression from scratch, we only consider a portion of the dataset for simplicity. The data can be found in `log_tcp_part.csv`, in which there are multiple columns, the last one is the class label, indicating the flow is from either **google** or **youtube**, and the rest are features. Your job is a binary classification task to classify the domain of each flow (row) **from scratch**, including:\n",
    "- Build a logistic regression model,\n",
    "- Evaluate the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca26eaa",
   "metadata": {},
   "source": [
    "1. Load the dataset.\n",
    "2. Get the list of features (columns 1 to 10).\n",
    "3. Add a new column and assign numerical class labels of -1 and 1 to google and youtube.\n",
    "4. Answering the following questions:\n",
    "    - How many features do we have?\n",
    "    - How many samples do we have in total?\n",
    "    - How many samples do we have for each class? Are they similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b1d79c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " google sample: 10000\n",
      "youtube sample: 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_msgsize_count</th>\n",
       "      <th>c_pktsize6</th>\n",
       "      <th>c_msgsize4</th>\n",
       "      <th>s_msgsize4</th>\n",
       "      <th>s_pktsize2</th>\n",
       "      <th>s_rtt_cnt</th>\n",
       "      <th>s_rtt_std</th>\n",
       "      <th>s_msgsize5</th>\n",
       "      <th>c_msgsize6</th>\n",
       "      <th>c_sit3</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1418</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>google</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.466732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>google</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.413304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>google</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1418</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>google</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1418</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>google</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1418</td>\n",
       "      <td>3</td>\n",
       "      <td>22.224528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.334</td>\n",
       "      <td>youtube</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "      <td>1418</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>1.252</td>\n",
       "      <td>youtube</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1205</td>\n",
       "      <td>0</td>\n",
       "      <td>531</td>\n",
       "      <td>4</td>\n",
       "      <td>15.323660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4975.694</td>\n",
       "      <td>youtube</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>690</td>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>4</td>\n",
       "      <td>17.997651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1719.125</td>\n",
       "      <td>youtube</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>youtube</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       c_msgsize_count  c_pktsize6  c_msgsize4  s_msgsize4  s_pktsize2  \\\n",
       "0                    1           0           0           0        1418   \n",
       "1                    1           0           0           0           0   \n",
       "2                    1           0           0           0           0   \n",
       "3                    1           0           0           0        1418   \n",
       "4                    1           0           0           0        1418   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "19995                4           0          37           0        1418   \n",
       "19996                6          45          45          57        1418   \n",
       "19997                4           0        1205           0         531   \n",
       "19998                4           0         690           0         767   \n",
       "19999                1           0           0           0           0   \n",
       "\n",
       "       s_rtt_cnt  s_rtt_std  s_msgsize5  c_msgsize6    c_sit3    class  label  \n",
       "0              0   0.000000           0           0     0.000   google      1  \n",
       "1              3   0.466732           0           0     0.000   google      1  \n",
       "2              3   0.413304           0           0     0.000   google      1  \n",
       "3              1   0.000000           0           0     0.000   google      1  \n",
       "4              0   0.000000           0           0     0.000   google      1  \n",
       "...          ...        ...         ...         ...       ...      ...    ...  \n",
       "19995          3  22.224528           0           0     3.334  youtube     -1  \n",
       "19996          2   0.000000          45          45     1.252  youtube     -1  \n",
       "19997          4  15.323660           0           0  4975.694  youtube     -1  \n",
       "19998          4  17.997651           0           0  1719.125  youtube     -1  \n",
       "19999          1   0.000000           0           0     0.000  youtube     -1  \n",
       "\n",
       "[20000 rows x 12 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"log_tcp_part.csv\")\n",
    "features = df.columns.values[:-1]\n",
    "df[\"label\"] = df[\"class\"].apply(lambda x: 1 if x==\"google\" else -1)\n",
    "df_google = df.loc[df[\"class\"] == \"google\"]\n",
    "print(f\" google sample: {len(df_google)}\\nyoutube sample: {len(df) - len(df_google)}\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17de4a26",
   "metadata": {},
   "source": [
    "### 2. Implement your logistic regression learning algorithm\n",
    "Here you will need to construct a class in which you need to define two functions besides the class initialization:\n",
    "- `fit`. In this method you will perform ERM. Learn the parameters of the model (i.e., the hypothesis h) from training with gradient descent\n",
    "- `predict`. In this method given one  sample x (or more) you will perform the inference $sign(h(x))$ to obtain class labels.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- The linear function used in the logistic regression is the following: $h(x)=w^T x +b $, where b is a scalar bias.\n",
    "- Logistic loss: $L((x,y),h)=\\log(1+e^{-y h(x)})$\n",
    "- ERM: $\\min_{w,b} f(w,b)=\\frac{1}{m}\\sum_{i=1}^{m} \\log(1+e^{-y^{(i)} h(x^{(i)})})$\n",
    "- Gradient for weight: $\\nabla_w f(w,b) = \\frac{1}{m} \\sum_i \\frac{-y^{(i)}x^{(i)}}{(1+e^{+y^{(i)}h(x^{(i)})})}$\n",
    "- Gradient for bias: $\\nabla_b f(w,b)= \\frac{1}{m} \\sum_i \\frac{-y^{(i)}}{(1+e^{+y^{(i)}h(x^{(i)})})}$\n",
    "- Update the parameters: $w \\leftarrow w - \\alpha \\nabla w$, $b \\leftarrow b - \\alpha  \\nabla b$\n",
    "\n",
    "Notice that the sigmoid function $f(z) = \\frac{1}{1 + e^{-z}}$ appears multiple times. You can write also a method for the sigmoid function to help you in the computation. By considering f(z), the gradients rewrite as:\n",
    "\n",
    "- Gradient for weight: $\\nabla_w f(w,b) = \\frac{1}{m} \\sum_i (-y^{(i)}x^{(i)})({f(-y^{(i)} h(x^{(i)})}))  $\n",
    "- Gradient for bias: $\\nabla_b f(w,b) = \\frac{1}{m} \\sum_i (-y^{(i)})({f(-y^{(i)} h(x^{(i)})}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca48b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate, num_iterations):\n",
    "        self.a = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.w = np.zeros(X.shape[1])\n",
    "        self.bias = 0\n",
    "\n",
    "        m = X.shape[0]\n",
    "\n",
    "        for _ in range(self.num_iterations):\n",
    "            h_x = np.dot(X, self.w) + self.bias\n",
    "\n",
    "            # loss = np.log(1 + np.exp(-y * h_x))\n",
    "\n",
    "            dw = (1/m) * np.dot(X.T, self.sigmoid(-y * h_x) * -y)\n",
    "            db = (1/m) * np.sum(self.sigmoid(-y * h_x) * -y)\n",
    "\n",
    "            self.w -= self.a * dw\n",
    "            self.bias -= self.a * db\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(np.dot(X, self.w) + self.bias)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c44e29",
   "metadata": {},
   "source": [
    "### 3. Use the model\n",
    "- Initialize your model with predefined learning rate of `0.1` and iterations of `100`.\n",
    "- Fit your model with features and targets.\n",
    "- Get the prediction with features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58a6ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dosisido/Documents/ml4n-2024/.venv/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(0.1, 100)\n",
    "model.fit(df[features].values, df[\"label\"])\n",
    "predictions = model.predict(df[features].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9633f1b",
   "metadata": {},
   "source": [
    "### 4. Model evaluation\n",
    "With predicted class labels and ground truths, we now evaluate the model performance through confusion matrix and numerical metrics. Specifically, you need to derive the following:\n",
    "- Confusion matrix - Note that, you should indicate the corresponding quantity of each element in the table. Here positive is class 1 and negative is class -1:\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    " & \\textbf{Predicted Positive} & \\textbf{Predicted Negative} \\\\\n",
    "\\hline\n",
    "\\textbf{Actual Positive} & \\text{True Positive (TP)} & \\text{False Negative (FN)} \\\\\n",
    "\\hline\n",
    "\\textbf{Actual Negative} & \\text{False Positive (FP)} & \\text{True Negative (TN)} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "- Precision of each class and the average value:\n",
    "$\\frac{\\text{True Positive (TP)}}{\\text{True Positive (TP) + False Positive (FP)}}$\n",
    "- Recall of each class and the average value:\n",
    "$\\frac{\\text{True Positive (TP)}}{\\text{True Positive (TP) + False Negative (FN)}}$\n",
    "- F1-score of each class and the average value:\n",
    "$F_1 = \\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$\n",
    "- Accuracy:\n",
    "$\\frac{\\text{True Positive (TP) + True Negative (TN)}}{\\text{True Positive (TP) + True Negative (TN) + False Positive (FP) + False Negative (FN)}}$\n",
    "- Answering the following questions:\n",
    "    - Do you have same performance between classes? If not, which one performs better?\n",
    "    - Change the parameters of learning rate or number of iterations. Do you have same performance? Better or Worse? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e0e4503c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Actual positive  Actual negative\n",
      "Predicted positive             7507             3271\n",
      "Predicted negative             2493             6729\n",
      "         precision    recall  f1-score  accuracy\n",
      "1         0.696511  0.750700  0.722591    0.7118\n",
      "-1        0.672900  0.729668  0.700135    0.7118\n",
      "average   0.684706  0.740184  0.711363    0.7118\n"
     ]
    }
   ],
   "source": [
    "y =  df[\"label\"]\n",
    "TP = sum((y[i] == 1) and (predictions[i] == 1) for i in range(len(y)))\n",
    "FN = sum((y[i] == 1) and (predictions[i] == -1) for i in range(len(y)))\n",
    "FP = sum((y[i] == -1) and (predictions[i] == 1) for i in range(len(y)))\n",
    "TN = sum((y[i] == -1) and (predictions[i] == -1) for i in range(len(y)))\n",
    "\n",
    "confusion_matrix = pd.DataFrame.from_dict({\n",
    "    \"Actual positive\":{\n",
    "        \"Predicted positive\":TP,\n",
    "        \"Predicted negative\":FN,\n",
    "    },\n",
    "    \"Actual negative\":{\n",
    "        \"Predicted positive\":FP,\n",
    "        \"Predicted negative\":TN,\n",
    "    }\n",
    "})\n",
    "print(confusion_matrix)\n",
    "\n",
    "accuracy = (TP + TN) / (TP+FN+FP+TN)\n",
    "\n",
    "#class 1\n",
    "precision_pos = TP / (TP + FP)\n",
    "recall_pos = TP / (TP + FN)\n",
    "f1_pos = 2 * (precision_pos * recall_pos) / (precision_pos + recall_pos) if precision_pos + recall_pos != 0 else 0\n",
    "\n",
    "\n",
    "precision_neg = TN / (TN + FP)\n",
    "recall_neg = TN / (TN + FN)\n",
    "f1_neg = 2 * (precision_neg * recall_neg) / (precision_neg + recall_neg) if precision_neg + recall_neg != 0 else 0\n",
    "\n",
    "# Average Values\n",
    "avg_precision = (precision_pos + precision_neg) / 2\n",
    "avg_recall = (recall_pos + recall_neg) / 2\n",
    "avg_f1 = (f1_pos + f1_neg) / 2\n",
    "\n",
    "df_metrics = pd.DataFrame({\n",
    "    \"precision\": [precision_pos, precision_neg, avg_precision],\n",
    "    \"recall\": [recall_pos, recall_neg, avg_recall],\n",
    "    \"f1-score\": [f1_pos, f1_neg, avg_f1],\n",
    "    \"accuracy\": [accuracy, accuracy, accuracy]\n",
    "}, index=[\"1\", \"-1\", \"average\"])\n",
    "\n",
    "print(df_metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
